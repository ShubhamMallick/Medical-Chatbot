{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8307f90",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'medibot (Python 3.10.16)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n medibot ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fa629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDFs from directory\n",
    "def load_pdf_file(data_dir):\n",
    "    loader = DirectoryLoader(data_dir, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf_file(r'C:\\Users\\DELL\\OneDrive\\Desktop\\Hackathon\\Doc_Chatbot\\Medical-Chatbot\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into chunks\n",
    "def text_split(extracted_data):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    return splitter.split_documents(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73616f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Number of chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf824614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sentence-transformers model\n",
    "def download_hugging_face_embeddings():\n",
    "    return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check an embedding shape\n",
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Embedding dimension:\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e090c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create FAISS vector store\n",
    "docsearch = FAISS.from_documents(documents=text_chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use retriever\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82809b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generation pipeline\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=300,\n",
    "    temperature=0.7,\n",
    "    top_k=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "class HuggingFacePipelineLLM(BaseLanguageModel):\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def invoke(self, prompt: str):\n",
    "        result = self.pipeline(prompt, return_full_text=False)[0]['generated_text']\n",
    "        return result\n",
    "\n",
    "llm = HuggingFacePipelineLLM(llm_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35092a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt with system message\n",
    "system_prompt = (\n",
    "    \"You are an assistant for medical question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, say that you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b184a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangChain-compatible RAG chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the RAG chain\n",
    "question = \"What is Acne\"\n",
    "response = rag_chain.invoke({\"input\": question})\n",
    "print(\"Answer:\", response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4735a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a23506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d705699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d9756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788e02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fac20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef31ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
